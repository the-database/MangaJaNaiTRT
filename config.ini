[paths]
; Path to the folder or file to upscale
input_path = /path/to/input/images

; Path to ONNX model
input_onnx = ./onnx/4x_IllustrationJaNai_V3denoise_DAT2_27k_bf16_fp32_op23_dynamo.onnx

; Output directory for upscaled images
output_dir = /path/to/upscales


[output]
; png, jpg, webp, avif
format = png

; Output file suffix
note = mangajanai

; Global quality for lossy formats (jpg, webp, avif)
; PNG will ignore this.
quality = 95

; WebP-specific: when true, force lossless and ignore quality
webp_lossless = false


[tiling]
; Dynamic shape configuration for engine building and inference
; Format: width, height

; Minimum tile size the engine will support
dynamic_shape_min = 32,32

; Optimal tile size (TensorRT optimizes for this)
dynamic_shape_opt = 512,512

; Maximum tile size the engine will support
dynamic_shape_max = 512,512

; Tile alignment - tiles will be padded to multiples of this value
; Set to 1 for ESRGAN, Compact, etc. (no alignment needed)
; Set to 16 for windowed transformers (HAT, DAT, SwinIR, etc.)
tile_align = 16

; Overlap between tiles for seamless blending
tile_overlap = 16


[trt]
; TensorRT precision
; Safe for CNNs like ESRGAN, Compact, etc., cannot be used for large transformers
use_fp16 = false

; Best for large transformers (HAT, DAT, SwinIR, etc.)
use_bf16 = true

; Batch size - keep at 1 for heavy transformer networks
; Only increase if you have VRAM headroom with lightweight models
batch_size = 1

; CUDA device index
device_id = 0

; TensorRT builder config
; Scratch workspace, in GiB
workspace_gb = 4

; TensorRT builder optimization level
; 0 (fast build) .. 5 (max perf, long build)
opt_level = 3


[runtime]
; Number of images to prefetch
prefetch_images = 1

; Max size of the save queue
; Larger = more RAM usage
save_queue_maxsize = 4

; Number of save threads
num_save_threads = 2
